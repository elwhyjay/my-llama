# MY OWN LLAMA

## llama 구현하기

- [] rotary embedding 
- [] GQA
- [x] rms-normalization 
- [] SwiGLU
- [] feedforward
- [] attention
- [] transformer block

## TODO

### inference 관련 구현

- page attention 
- speculative decoding 
- kv cache 
